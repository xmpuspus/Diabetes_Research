{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 999\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, \\\n",
    "                             AdaBoostClassifier, \\\n",
    "                             GradientBoostingClassifier, \\\n",
    "                             ExtraTreesClassifier, \\\n",
    "                             BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.externals import joblib as jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_threshold(predict_proba, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in predict_proba.T[1]])\n",
    "\n",
    "def process_persample(classifier, train_data, train_label, test_data, test_label, th):\n",
    "    mod = classifier.fit(train_data, train_label)\n",
    "    probas_ = classifier.predict_proba(test_data)\n",
    "    pred = predict_threshold(probas_, th)\n",
    "    confusion_ = confusion_matrix(test_label, pred, labels=None)\n",
    "    score = np.round(accuracy_score(test_label, pred), 3)\n",
    "    fpr, tpr, thresholds = roc_curve(test_label, probas_[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return score, confusion_, [fpr, tpr, thresholds, roc_auc]\n",
    "\n",
    "def process_classifiers(classifiers, df_train, df_test, df_validate, y_train, y_test, y_validate, th):\n",
    "    \n",
    "    train_f = df_train\n",
    "    train_l = y_train\n",
    "\n",
    "    test_f = df_test\n",
    "    test_l = y_test\n",
    "    \n",
    "    validate_f = df_validate\n",
    "    validate_l = y_validate\n",
    "    \n",
    "    index = [re.findall('\\w*', str(x))[0] for x in classifier]\n",
    "    \n",
    "    params = {\"test\" : [test_f,test_l], \"validate\" : [validate_f,validate_l]}\n",
    "    #params = {\"test\" : [test_f,test_l]}\n",
    "    accuracy_table = []\n",
    "    \n",
    "    with sns.axes_style(\"darkgrid\"):\n",
    "        fig, axes = plt.subplots(int(np.ceil(9/ 3)), 3, sharex='all', sharey='all', figsize=(12, 12))\n",
    "\n",
    "        for ax, i in zip(axes.flatten(), range(len(classifier))):\n",
    "            a = []\n",
    "            \n",
    "            for keys in params:\n",
    "                acc, conf_m, roc_ = process_persample(classifier[i], train_f, train_l, \\\n",
    "                                                  params[keys][0], params[keys][1], th)\n",
    "                a.append(acc)\n",
    "                \n",
    "                x_roc = np.insert(roc_[0],0,0, axis=0)\n",
    "                y_roc = np.insert(roc_[1],0,0, axis=0)\n",
    "                ax.plot(x_roc, y_roc ,lw=1, label = 'ROC %s (area = %0.4f)' % (keys, roc_[3]))\n",
    "        \n",
    "            ax.set_title(re.findall('\\w*', str(classifier[i]))[0], size = 13)\n",
    "            ax.legend(loc=4, fontsize=11)\n",
    "            \n",
    "            accuracy_table.append(a)\n",
    "            ax.set_xlim(-0.1,1.1)\n",
    "            ax.set_ylim(-0.1,1.1)\n",
    "            ax.axis(\"equal\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    return pd.DataFrame(np.array(accuracy_table), columns = ['test accuracy','validate_accuracy'], \\\n",
    "                        index = index)\n",
    "\n",
    "\n",
    "classifier = [LogisticRegression(),\n",
    "              DecisionTreeClassifier(),\n",
    "              RandomForestClassifier(),\n",
    "              AdaBoostClassifier(), \n",
    "              GradientBoostingClassifier(),\n",
    "              ExtraTreesClassifier(),\n",
    "              BaggingClassifier(),\n",
    "              KNeighborsClassifier(),\n",
    "              GaussianNB()\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_classifiers(classifier, X_train, X_test, X_validate, y_train, y_test, y_validate, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cgm-research]",
   "language": "python",
   "name": "conda-env-cgm-research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
